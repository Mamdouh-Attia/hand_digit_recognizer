{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.io import imshow, show\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import ndimage\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from PreProcessing.Processing import Processing\n",
    "from FeaturesExtraction.Features import Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Processing_obj=Processing('dataset2_large')\n",
    "data_train = []\n",
    "labels = []\n",
    "\n",
    "rotation_angles = [10, -10, 20, -20]  # Define a list of angles for data augmentation\n",
    "\n",
    "data_trian,labels=Processing_obj.ReadAndProcess(rotation_angles)\n",
    "\n",
    "print(f'Number of images loaded: {len(data_train)}')\n",
    "\n",
    "# Get 20 random indices from data_train\n",
    "random_indices = np.random.choice(len(data_train), size=20, replace=False)\n",
    "\n",
    "# Plot the 20 random grayscale images\n",
    "fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(12, 10))\n",
    "\n",
    "Processing_obj.ShowSomeImages(axes,data_train,labels,random_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_obj=Features()\n",
    "\n",
    "hog_features = [Features_obj.extract_hog_features(image) for image in data_train]\n",
    "print(f'HOG feature vector size: {hog_features[0].shape}')\n",
    "\n",
    "lbp_features = [Features_obj.extract_lbp_features(image) for image in data_train]\n",
    "\n",
    "# Flatten LBP features\n",
    "flattened_lbp_features = [Features_obj.lbp_feature.flatten() for lbp_feature in lbp_features]\n",
    "print(f'Length of flattened LBP features: {len(flattened_lbp_features)}')\n",
    "\n",
    "# Concatenate HOG, LBP, and Gabor features\n",
    "combined_features = np.hstack((hog_features, flattened_lbp_features))\n",
    "\n",
    "print(f'Combined HOG, LBP features shape: {combined_features.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=0.7)\n",
    "reduced_features = pca.fit_transform(combined_features)\n",
    "print(f'Reduced features shape: {reduced_features.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(n_neighbors=7),\n",
    "    # DecisionTreeClassifier(),\n",
    "    # RandomForestClassifier(),\n",
    "    # AdaBoostClassifier(),\n",
    "    # GradientBoostingClassifier(),\n",
    "    # LogisticRegression(),\n",
    "    MLPClassifier(),\n",
    "    SVC(kernel='linear', C=1)\n",
    "]\n",
    "\n",
    "# Initialize a dictionary to store the classifier names and their accuracies\n",
    "classifier_accuracies = {clf.__class__.__name__: [] for clf in classifiers}\n",
    "\n",
    "# Define the number of iterations\n",
    "num_iterations = 15\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(reduced_features, labels, test_size=0.1)\n",
    "\n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    for clf in classifiers:\n",
    "        clf_name = clf.__class__.__name__\n",
    "        clf.fit(X_train, y_train)\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        classifier_accuracies[clf_name].append(accuracy)\n",
    "\n",
    "# Print all accuracies for each classifier and the average accuracy\n",
    "for clf_name, accuracies in classifier_accuracies.items():\n",
    "    print(f'{clf_name} accuracies: {accuracies}')\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    print(f'{clf_name} average accuracy: {avg_accuracy}\\n')\n",
    "\n",
    "# Print the classifier with the best average accuracy\n",
    "best_clf_name = max(classifier_accuracies, key=lambda x: np.mean(classifier_accuracies[x]))\n",
    "print(f'Best classifier: {best_clf_name} with average accuracy {np.mean(classifier_accuracies[best_clf_name])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
