{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pip\n",
    "pip.main(['install', 'rembg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import  data, color, feature\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# from rembg import remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resize_image(image):\n",
    "    return cv2.resize(image, (300, 300), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def apply_gaussian_blur(image):\n",
    "    return cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "def get_skin_mask_hsv(image):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lower_skin = (0, 20, 70)\n",
    "    upper_skin = (20, 255, 255)\n",
    "    return cv2.inRange(hsv_image, lower_skin, upper_skin)\n",
    "\n",
    "def get_skin_mask_ycrcb(image):\n",
    "    ycrcb_image = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    lower_skin = (0, 135, 85)\n",
    "    upper_skin = (255, 180, 135)\n",
    "    return cv2.inRange(ycrcb_image, lower_skin, upper_skin)\n",
    "\n",
    "def equalize_histogram(image):\n",
    "    ycrcb_image = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    channels = cv2.split(ycrcb_image)\n",
    "    channels[0] = cv2.equalizeHist(channels[0])\n",
    "    return cv2.cvtColor(cv2.merge(channels), cv2.COLOR_YCrCb2BGR)\n",
    "\n",
    "def preprocess_image(image):\n",
    "    resized_image = resize_image(image)\n",
    "    blurred_image = apply_gaussian_blur(resized_image)\n",
    "    \n",
    "    hsv_mask = get_skin_mask_hsv(blurred_image)\n",
    "    ycrcb_mask = get_skin_mask_ycrcb(blurred_image)\n",
    "    \n",
    "    skin_mask = cv2.bitwise_and(hsv_mask, ycrcb_mask)\n",
    "    \n",
    "    # Apply morphological operations to improve the skin mask\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    skin_mask = cv2.erode(skin_mask, kernel, iterations=2)\n",
    "    skin_mask = cv2.dilate(skin_mask, kernel, iterations=2)\n",
    "    \n",
    "    # Apply the skin mask to the original image\n",
    "    skin_segment = cv2.bitwise_and(blurred_image, blurred_image, mask=skin_mask)\n",
    "    \n",
    "    # Convert the skin segment to grayscale and apply thresholding\n",
    "    gray_image = cv2.cvtColor(skin_segment, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh_image = cv2.threshold(gray_image, 175, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    return thresh_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=[]\n",
    "def test_stages(channel, index):\n",
    "    # Load a sample images from the dataset\n",
    "\n",
    "    sample_image_path = 'dataset/men/' + channel + '/' + channel + '_men (' + str(index) + ').JPG'\n",
    "    img = cv2.imread(sample_image_path)\n",
    "    \n",
    "    # Preprocess the image\n",
    "    img = cv2.imread(sample_image_path, -1)\n",
    "\n",
    "    rgb_planes = cv2.split(img)\n",
    "\n",
    "    result_planes = []\n",
    "    result_norm_planes = []\n",
    "    skin_mask=\"\"\n",
    "    skeleton=\"\"\n",
    "    for plane in rgb_planes:\n",
    "        dilated_img = cv2.dilate(plane, np.ones((3,3), np.uint8))\n",
    "        bg_img = cv2.medianBlur(dilated_img, 25)\n",
    "        diff_img = np.max(dilated_img) - cv2.absdiff(plane, bg_img)\n",
    "        norm_img = cv2.normalize(diff_img,None, alpha=170, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "        result_planes.append(diff_img)\n",
    "        result_norm_planes.append(norm_img)\n",
    "    result = cv2.merge(result_planes)\n",
    "    result_norm = color.rgb2gray(cv2.merge(result_norm_planes))\n",
    "\n",
    "    cv2.imwrite('shadows_out.png', result)\n",
    "    cv2.imwrite('shadows_out_norm.png', result_norm)\n",
    "    hogVec, hogVis = feature.hog(result_norm, visualize=True)\n",
    "    data_train.append(hogVec.reshape(hogVec.shape[0],1))\n",
    "    return data_train\n",
    "# Test the stages of the preprocessing pipeline by atterating over the channel with 5 indexes\n",
    "data_train_4=[]\n",
    "data_train_2=[]\n",
    "data_train_3=[]\n",
    "for index in range(1, 5):\n",
    "   data_train_4=test_stages(str(4), str(index))\n",
    "data_train=[]\n",
    "for index in range(1, 6):\n",
    "   data_train_2=test_stages(str(2), str(index))\n",
    "data_train=[]\n",
    "for index in range(1, 6):\n",
    "   data_train_3=test_stages(str(3), str(index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "obj_shape=data_train_4[0].shape\n",
    "X=[data_train_4[0].reshape(obj_shape[1],obj_shape[0]),data_train_2[0].reshape(obj_shape[1],obj_shape[0]),data_train_4[2].reshape(obj_shape[1],obj_shape[0]),data_train_4[1].reshape(obj_shape[1],obj_shape[0]),data_train_2[3].reshape(obj_shape[1],obj_shape[0]),data_train_2[2].reshape(obj_shape[1],obj_shape[0]),data_train_2[1].reshape(obj_shape[1],obj_shape[0]),data_train_3[0].reshape(obj_shape[1],obj_shape[0]),data_train_3[3].reshape(obj_shape[1],obj_shape[0])]\n",
    "Y=[4,2,4,4,2,2,2,3,3]\n",
    "print(np.array(X).shape,X[0].shape,len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#will put the features in the dataframe\n",
    "print(obj_shape[0])\n",
    "df=pd.DataFrame(columns=[ i for i in range(14971068)])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X)):\n",
    "    x_flatten=(X[i].flatten()).reshape(-1)\n",
    "    df.append([x_flatten]) \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to save a 95% from the usefull features\n",
    "pca=PCA(.95)\n",
    "x_pca=pca.fit_transfrom(df)\n",
    "print(x_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data to train and test data\n",
    "from sklearn .model_selection import train_test_split\n",
    "X_train,x_test,y_train,y_test=train_test_split(x_pca,Y,test_size=0.2,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a svm model \n",
    "clf = svm.SVC(kernel='linear')\n",
    "#fit the data to the model\n",
    "clf.fit(X_train,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
